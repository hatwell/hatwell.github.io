---
layout: post
title: my first production bug
summary:
date: 2023-05-18
image: images/prod_bug/sunset.png
---

This week marked an important event ğŸ¾Â - I have been at my current job since the first of March, and itâ€™s been great, but one thing was missing. I hadnâ€™t broken anything yet. This week, that changed. Hereâ€™s what happenedâ€¦

Part of our platform at Vypr is a service called [VyPops](https://vyprclients.com/vypops/) . This allows out clients to get customer feedback via video insights, and is proving popular with our clients, like [Marks and Spencer](https://vyprclients.com/marks-spencer/). We got a message in our team Slack channel from one of our co-workers asking â€œHave any VyPops responses come through for this question yet? It doesnâ€™t look like there are any?â€ I check the database - yes, there appear to be twenty-five answers. She comes back to us saying that they might exist in the database but they canâ€™t see any in the front end of the platform. Is there any issue with them coming through? I log into the platform and see that yep, there arenâ€™t any videos visible.

We begin investigating. Eventually, we get to the logs for the third party service that uploads the videos, and can see theyâ€™re full of errors. The error shows an incorrectly formatted URL, so thatâ€™s causing a 404, which is blocking the upload entirely. Ok, where does that URL come from? Eventually we find it, and itâ€™s generated by passing a file path to a rails method called `helpers.image_url` . Doesnâ€™t seem very helpful if you ask me.

My colleague has the smart idea to look at previous successful uploads, and the URL value in those is a) valid and b) has a different base URL - one from CloudFront rather than one of ours. Whatâ€™s going on?

We look back through the video service upload logs to see when the errors started occurring. I keep clicking back through the pages. This is taking too long. Finally, I find it. The last successful upload was at about 13:55, five days ago. As my colleague says â€œDidnâ€™t we do a release that day?â€, the sinking feeling in my stomach tells me the answer. Yes, we did. We did a release at about 14:00. Full of my code ğŸ˜¬

First, we need to deploy a fix to get the system running again âš’ï¸. Hardcode the URL for now, thatâ€™ll allow the requests to go through successfully. We merge and release this quickly. Now weâ€™re operational again, and I can take a deep breath and start investigating ğŸ•µï¸.

I find a quick way to use the tests to show me the URL thatâ€™s being generated. Checking out each commit in turn starting with the one that got released. Running the tests to find the commit where the URL goes from valid to invalidâ€¦.yep, itâ€™s one of my merged PRs. Ok, so Iâ€™ve successfully isolated the commit that causes the problem. Whatâ€™s next?

Go through the commit file by file and find the file where the breaking change is. I get through a few and Iâ€™m not there. I figure, for now, I can skip the Javascript files, as itâ€™s a function in the Ruby code thatâ€™s causing the problem. I donâ€™t completely rule them out because honestly, you never really know with computers, but I figure Iâ€™ll prioritise checking the Ruby changes.

After checking a few files that donâ€™t affect the output, [I get to the main routes routes configuration file](https://guides.rubyonrails.org/routing.html). Copy over the changes, and run the tests. Yep, thatâ€™s the one. Makes sense! The problem is to do with a URL being generated, a route to a resource. Maybe I could have started there. Iâ€™ll know that for next time.

Eventually, it turns out that I erroneously included a built-in function in the rails routing array that I thought I needed for a feature. I didnâ€™t actually need it, but it had the side effect of breaking the asset URL generator. But how? I _think_ itâ€™s because we have an `Image` resource that uses the `/images` route, and something about generating the route I didnâ€™t need (the `:update` route) clashed with the way that Rails generates the URL for files in `assets/images` but Iâ€™m still not certain. More research needed! ğŸ“š

This has also shown a blind spot regarding Rails ğŸ’. The great thing about Rails is that it does loads of stuff for you. The not great thing about Rails is that it does lots of stuff for you and obfuscates a lot of what itâ€™s doing, and the how and the why. Itâ€™s good to have found out pretty early on that my mental model of route configuration isnâ€™t right, and I need to understand it better. Not least because routing is very important!

This bug also revealed that we had a service failing silently since the release, and thatâ€™s just not OK. It had been pumping out errors into the logs because it was repeatedly making a request that involved this invalid URL, and we didnâ€™t know about it. This was a recently built microservice - had it been an issue with the main monolith that powers our platform, weâ€™d have known much more quickly. Luckily, we use PaperTrail and NewRelic on Heroku, so Iâ€™ve been able to set up a Slack integration that sends a message to our development channel if we get more than twenty errors in a minute, so that we wonâ€™t get caught out by something like this again. We canâ€™t completely stop ourselves from releasing bugs, but we can make it a lot easier to catch them.

Working on a small team and a relatively small system means that when issues like this arise, we can swarm to address them, and the fact that we were able to have a fix released within a couple of hours of the problem being raised by a system user is a real benefit of our small team.

The autonomy we have has also meant that Iâ€™ve been able to identify system improvements (eg the Slack alerts, looking at adding some better error handling for the request that was failing on the 404) and implement them pretty quickly. Being able to learn lessons from this mistake and use those lessons to make the system more resilient is a big benefit of being part of a small agile team.
